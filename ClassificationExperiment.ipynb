import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_svmlight_file
from sklearn.model_selection import train_test_split

X, y = load_svmlight_file("australian_scaled")
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, random_state=20)
eta = 0.001
C=0.1
m, n = np.shape(X_train)



y_train = y_train.reshape(462, 1)
y_valid = y_valid.reshape(228, 1)
LossFtrain = np.zeros((462, 1))
LossFvalid = np.zeros((228, 1))

b = np.random.rand(1)
w = np.random.rand(n)
w = w.reshape(n, 1)
b = b.reshape(1,1)
ttgw=np.zeros((1,n))
ttgb=np.zeros((1,1))

for j in range(100):
    for i in range(462):
        f = X_train[i]*w+b
        theta = 1-y_train[i,0]*f
        #threshold阈值 is 0
        LossFtrain[i] = max(0, theta)
        if i<228 :
            LossFvalid[i] = max(0, 1-y_valid[i]*(X_valid[i]*w+b))
        gw=-y_train[i,0]*X_train[i].T if theta > 0 else np.zeros((n,1))
        gb=-y_train[i] if theta > 0 else np.zeros((1,1))
        ttgw=ttgw+gw
        ttgb=ttgb+gb
    wgrad = w+C*ttgw
    bgrad = b+C*ttgb

    w = w-eta*(1/n)*ttgw
    b = b-eta*(1/n)*ttgb

    LossFtrainTotal=np.sum(LossFtrain)
    LossFvalidTotal=np.sum(LossFvalid)

    #Hinge loss
    L_train=np.square(w)/2+C*LossFtrainTotal
    L_valid=np.square(w)/2+C*LossFvalidTotal


correct=0

for i in range(228):
    if y_valid[i]*(X_valid[i]*w+b)>0 :
        correct=correct+1

accuracy = correct/228
print(accuracy)

num = np.arrange(100)
plt.figure(1)
plt.plot(num + 1, LossFtrainTotal[num], label="$trainLoss$")
plt.plot(num + 1, LossFvalidTotal[num], label="$validLoss$")
plt.legend()
plt.show()
